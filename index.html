<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Retrieval-based Disentangled Representation Learning with Natural Language Supervision">
  <meta name="keywords" content="VDR, Explainable, Disentangled Representation, Retriever>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Retrieval-based Disentangled Representation Learning with Natural Language Supervision </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            VDR: Retrieval-based <br> Disentangled Representation Learning <br> with Natural Language Supervision
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jzhoubu.github.io/">Jiawei Zhou</a><sup>1</sup>,</span>
            <span class="author-block">
              Xiaoguang Li<sup>2</sup>,</span>
            <span class="author-block">
              Lifeng Shang<sup>2</sup>,
            </span>
            <span class="author-block">
              Xin Jiang<sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://liuquncn.github.io/index_en.html">Qun Liu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://cse.hkust.edu.hk/~leichen/">Lei Chen</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong University of Science and Technology,</span>
            <span class="author-block"><sup>2</sup>Noahâ€™s Ark Lab</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=ZlQRiFmq7Y"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>OpenReview</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2212.07699.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/jzhoubu/vsearch"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
  We introduce <b>VDR</b> (<b>V</b>ocabulary <b>D</b>isentangled <b>R</b>etrieval),
  a bi-encoder retrieval framework that learns disentangled representations 
  of multi-modal data in a language model vocabulary space that is comprehensible to humans.
      <img src="./static/images/VDR-cover-page.png" alt="teaser">
      </h2>
      <h3 class="subtitle" style="max-width: 700px; margin: auto;">
        <div style="text-align: center;">
        <b>VDR</b> provides several advatanges:
          <div style="text-align: left;">
            <ol>
              <li> <span style="font-weight: bold;">Effective</span> multi-modal retrieval. </li>
              <li> <span style="font-weight: bold;">Efficient</span> and <span style="font-weight: bold;">low-resource</span> retrieval inference. </li>
              <li> <span style="font-weight: bold;">Explainable</span> data embeddings and
              <span style="font-weight: bold;">Transparency</span> reasoning and analysis. </li>
            </ol>
          </div>
        </div>
      </h3>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <span style="font-weight: bold;">Challenge</span>: Disentangled representation learning remains challenging 
            as the underlying factors of variation in the data do not naturally exist.
            The inherent complexity of real-world data makes it unfeasible to exhaustively enumerate and encapsulate 
            all its variations within a finite set of factors. 
          </p>
          <p>
            <span style="font-weight: bold;">Approach</span>: In this paper, we present Vocabulary Disentangled Retrieval (VDR), 
            a retrieval-based framework that harnesses natural language as proxies of the underlying data variation 
            to drive disentangled representation learning.
            Our approach employs a bi-encoder model to represent both data and natural language in a vocabulary space, 
            enabling the model to distinguish dimensions that capture intrinsic characteristics within data through its natural language counterpart, thus facilitating disentanglement. 
          </p>
          <p>
            <span style="font-weight: bold;">Results</span>: We extensively assess the performance of VDR across 15 retrieval benchmark datasets, covering text-to-text and cross-modal retrieval scenarios, as well as human evaluation. 
            Our experimental results compellingly demonstrate the superiority of VDR over previous bi-encoder retrievers with comparable model size and training costs, 
            achieving an impressive 8.7% improvement in NDCG@10 on the BEIR benchmark, a 5.3% increase on MS COCO, and a 6.0% increase on Flickr30k in terms of mean recall in the zero-shot setting. 
            Moreover, the results from human evaluation indicate that interpretability of our method is on par with SOTA captioning models.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Disentangled Representation on LM Vocabulary</h2>
        <div class="content has-text-justified">
          <p>
            <strong> What is Disentangled Representation? </strong><br>
            Disentangled representation [<a href="#ref1">1</a>] is a concept in machine learning 
            where the model learns to separate the underlying factors of variation in the data 
            into distinct units within its representation. 
            This means that each dimension of the representation captures a factor of variation, 
            making it easier to understand the learned representation.
          </p>

          <p>
            <strong> What are the benefits of disentangled representation? </strong><br>
            A well-disentangled representation independently captures underlying factors that explain the data, 
            thereby facilitating explainability, controllability, and debugability of machine learning. 
            Disentangled representations bring various benefits such as interpretability, adaptability to new tasks, 
            resilience to input variations, and streamlined feature manipulation.
          </p>

          <p>
            <strong> Why Disentangling Representation on LM Vocabulary Space? </strong><br>
            Real-world data is inherently complex and cannot be fully encapsulated by a limited set of attributes. 
            Natural language expressions adeptly represent diverse real-world objects and can be tokenized into a finite vocabulary space. 
            This vocabulary space serves as an effective proxy for capturing the variations within data.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> Demo </h2>
        <div class="content has-text-justified">
          <p>
            <strong> 1. Inspectation on Disentangled Representation </strong> <br>
            <img src="./static/images/cover-fig1.jpg" alt="embedding">
            <br>
            <strong> 2. Fine-grained Disentanglement </strong><br>
            <img src="./static/images/cover-fig3.jpg" alt="patch">
            <br>
            <strong> 3. Retrieval Reasoning </strong> <br>
            <img src="./static/images/cover-fig2.jpg" alt="patch">
            <strong> 4. More Examples </strong> <br>
            <img src="./static/images/cover-fig4.png" alt="patch">
            <br>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> How to use VDR</h2>
        <div class="content has-text-justified">
          <p>
            Please see our <a href="https://github.com/jzhoubu/VDR">GitHub repo</a> for all the code and data. 
            Below is an example demo code:
            <br>
            <iframe src="./static/images/example-code.html" width="100%" height="500px"></iframe>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="reference" id="reference">
  <div class="container is-max-desktop content">
    <h2 class="title">Reference</h2>
      <a name="ref1", href="https://arxiv.org/pdf/1206.5538.pdf" target="_blank"><p>[1] Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation Learning: A Review and New Perspectives.</p></a>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{zhou2024retrievalbased,
  title={Retrieval-based Disentangled Representation Learning with Natural Language Supervision},
  author={Jiawei Zhou and Xiaoguang Li and Lifeng Shang and Xin Jiang and Qun Liu and Lei Chen},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=ZlQRiFmq7Y}
}</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
